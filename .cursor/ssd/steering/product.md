# Product Overview

## Product Purpose

Eagle Eye AI（Castrel AI）是一个基于 AI 的智能可观测性平台，专注于自动化数据探索、服务发现和根因分析。通过 AI 技术自动分析日志、指标、链路和告警数据，快速发现系统中的服务、基础设施和数据路由关系，帮助运维团队快速定位和解决问题。

**核心问题**：
- 手动梳理服务拓扑和数据关系耗时费力
- 多数据源之间缺乏统一的数据映射和标准化
- 故障发生时根因定位效率低下
- 基础设施和服务实体难以自动发现和管理

## Target Users

### 主要用户

1. **平台运维人员（Platform SRE）**
   - **需求**：快速发现和管理系统中的服务、基础设施
   - **痛点**：需要手动维护服务清单和依赖关系，容易遗漏
   - **价值**：自动化服务发现，节省 70% 的梳理时间

2. **应用运维工程师（Application SRE）**
   - **需求**：理解数据路由和指标映射关系
   - **痛点**：多个监控系统的数据字段不统一，难以关联分析
   - **价值**：统一数据路由，实现跨数据源的关联分析

3. **故障响应团队（Incident Response Team）**
   - **需求**：快速定位故障根因
   - **痛点**：需要在多个系统间切换查看数据，效率低下
   - **价值**：AI 驱动的根因分析，减少 MTTR（平均修复时间）

### 次要用户

4. **DevOps 工程师**
   - **需求**：了解服务部署状态和依赖关系
   - **价值**：清晰的服务拓扑和实体管理

5. **系统架构师**
   - **需求**：全局视角查看系统架构和数据流
   - **价值**：自动化的架构发现和可视化

## Key Features

### 1. **AI 数据探索工作流（Data Exploration Workflow）**
自动化 AI 工作流，分析可观测性数据并发现服务、基础设施和数据路由

- **支持的数据类型**：Log、Metric、Trace、Alert
- **自动识别**：服务元数据、服务实体、基础设施实体、数据路由、指标元数据
- **多数据源支持**：Elasticsearch、Datadog、Prometheus、Doop、Graylog 等
- **AI 驱动**：基于 LangGraph 的智能工作流编排

### 2. **根因分析（Root Cause Analysis）**
AI 驱动的故障根因定位和分析

- **分层排障流程**：快速扫描 → 深度分析 → 根因推荐
- **多类型 Runbook**：支持主机、服务、K8s、服务端点等多种运维场景
- **状态持久化**：支持断点续传和故障恢复

### 3. **插件化数据源集成**
统一的插件架构，支持多种可观测性数据源

- **动态加载**：运行时加载和热更新
- **统一接口**：LogQueryService、MetricQueryService、TraceQueryService、AlertQueryService
- **易于扩展**：新增数据源只需实现接口，无需修改核心代码

### 4. **多租户 SaaS 架构**
支持多工作空间的数据隔离和管理

- **工作空间隔离**：通过 workspace_id 实现逻辑隔离
- **资源管理**：每个工作空间独立的配置和数据

## Business Objectives

- **提升运维效率**：自动化服务发现和数据映射，减少 70% 的手动梳理时间
- **降低 MTTR**：AI 驱动的根因分析，将故障定位时间从小时级降低到分钟级
- **统一数据视图**：跨数据源的数据标准化和关联分析
- **可扩展性**：插件化架构支持快速接入新的数据源和监控平台

## Success Metrics

- **服务发现覆盖率**：自动发现 90%+ 的服务和基础设施实体
- **根因分析准确率**：AI 推荐的根因准确率达到 80%+
- **数据源集成时间**：新增数据源集成时间 < 2 工作日
- **系统可用性**：99.9% 的可用性目标（8.76 小时/年停机时间）

## Product Principles

1. **AI 优先**：充分利用 AI 技术自动化重复性工作，释放人力专注于复杂决策
2. **插件化设计**：核心功能稳定，扩展功能通过插件实现，保持系统灵活性
3. **多租户支持**：从设计之初就考虑多租户场景，支持 SaaS 模式
4. **可观测性优先**：系统自身具备完整的可观测性，便于运维和调试
5. **渐进式增强**：核心功能稳定可靠，高级功能持续迭代优化

## Future Vision

### 短期（3-6 个月）
- 优化 LLM 调用成本和性能
- 实现 WebSocket 实时通知
- 增强监控和可观测性（Metrics、Tracing）

### 中期（6-12 个月）
- 支持本地 LLM 部署（Ollama）
- 实现细粒度权限控制（RBAC v2）
- 引入消息队列（Kafka/RabbitMQ）

### 长期（1-2 年）
- 多数据中心部署
- 全球化（多区域）
- 自动化 AI 训练和优化
- 完整的 AIOps 闭环

